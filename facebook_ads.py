# -*- coding: utf-8 -*-
"""Facebook Ads.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OoEnDm9eBjQxPDrp5llGbaAK1843fwV7

# Importing the Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# Importing the Dataset"""

dataset = pd.read_csv('Facebook_Ads_2.csv', encoding='ISO-8859-1')

dataset.head()

dataset.tail()

"""# Visualization of dataset"""

clicked = dataset[dataset['Clicked']==1]
not_clicked = dataset[dataset['Clicked']==0]

clicked.head()

print("Total =", len(dataset))

print("Number of customers who clicked on Ad =", len(clicked))
print("Percentage Clicked =", 1.*len(clicked)/len(dataset)*100.0, "%")
 
print("Did not Click =", len(not_clicked))
print("Percentage who did not Click =", 1.*len(not_clicked)/len(dataset)*100.0, "%")

sns.scatterplot(dataset['Time Spent on Site'], dataset['Salary'], hue = dataset['Clicked'])

sns.jointplot(x= dataset['Time Spent on Site'], y=dataset['Salary'], kind='scatter', hue = dataset['Clicked'])

plt.figure(figsize= (5,5))
sns.boxplot(x= 'Clicked', y= 'Salary', data = dataset)

plt.figure(figsize= (5,5))
sns.boxplot(x= 'Clicked', y= 'Time Spent on Site', data = dataset)

dataset['Salary'].hist(bins = 20)

dataset['Time Spent on Site'].hist(bins = 40)

"""# Cleaning the Data"""

dataset.head()

dataset.drop(['Names', 'emails', 'Country'], axis = 1, inplace = True)

dataset

X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

"""# Splitting the dataset into training and testset"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

X_train

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# Training the dataset"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, y_train)

"""# Predicting the test set Result"""

y_pred_train = classifier.predict(X_train)
print(np.concatenate((y_pred_train.reshape(len(y_pred_train),1), y_train.reshape(len(y_train),1)),1))

y_pred = classifier.predict(X_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

"""# Make Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score
cm_1 = confusion_matrix(y_train, y_pred_train)
print(cm_1)
accuracy_score(y_train, y_pred_train)

from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)



from sklearn.metrics import classification_report
sns.heatmap(cm_1, annot= True, fmt = 'd')

print(classification_report(y_train, y_pred_train))

print(classification_report(y_test, y_pred))

"""# Visualisation on training set"""

from matplotlib.colors import ListedColormap
X_set, y_set = sc.inverse_transform(X_train), y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),
                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))
plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Facebook Ads (Training set)')
plt.legend()
plt.show()

from matplotlib.colors import ListedColormap
X_set, y_set = sc.inverse_transform(X_test), y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),
                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))
plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Facebook Ads (Test set)')
plt.legend()
plt.show()